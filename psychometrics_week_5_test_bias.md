# (5/6) Psychometrics II - Prep Notes

## Week 5 - Test Bias

- The **reliability** of test scores can be compromised by **measurement error**, and the **validity** of test score interpretations can be compromised by **response biases** that systematically obscure the psychological differences among respondents.
- We discuss two important forms of test bias and the methods we can use to detect those biases. The two types of biases reflect biases in the meaning of a test, and biases in the use of a test:
      - **Construct bias** (also called measurement bias/internal bias) occurs when a test has different meanings for two groups, in terms of the precise construct that the test is intended to measure. Construct bias concerns the relationship of observed scores to true scores on a psychological test. If the relationship of observed scores to true scores is systematically different for different groups, then we might conclude that the test is biased. Construct bias can lead to situations where two groups have **the same average true score but different averages on observed scores on a test of the construct**.
      - **Predictive bias** (also called differential validity/external bias) occurs when a test's use has different implications for two groups. Predictive bias has to do with the relationship between scores on two different tests. One of these tests (the predictor test) is thought to provide values that can be used to predict scores on the other test (the outcome test/criterion measure). For example, we might use SAT scores to predict first-year GPA scores. In such cases, SAT scores would be the predictor test, and GPA scores would be the outcome test/criterion measure. In this context, test bias concerns the extent to which the link between predictor test true scores and criterior scores differs fo the two groups. If the SAT score is more strongly predicitive of GPA for one group than for another, then the SAT suffers from predictive bias, in terms of its use as a predictor of GPA.
- These two types of bias -construct and predicitve- are independent. Therefore, a test might have no consturct bias but suffer from predictive bias, or vice versa. For example, the SAT might accurately reflect true differences in academic aptitude among groups of people (and thus have no construct bias), but academic aptitude might not be associated with GPA scores equally for two different groups of people (and thus the SAT would have predictive bias).

- Two categories of procedures can be used to identify test score bias:
      1. Internal methods to identify construct bias
      2. External methods to identify predicitive bias

(Test score bias in both cases is a theoretical concept, as both types of bias depend on the theoretical notion of a true score. In reality, there is no single way to detect test score bias any more than there is a single way to directly calculate psychometric test score properties such as reliability or validity. There are, however, ways to stimate the degree to whoch test bias exists.)

(Another important comment regarding the definition and detection of test bias is that the existence of a group different does not necessarily mean that the test scores are biased.)

### Detecting construct bias: Internal evaluation of a test

- Construct bias, as implied by its name, is related to the meaning of test scores. If a test suffers from construct bias, then the scores on a test might have different meanings for different groups of people. In this case, it does not make psychological sense to compare test scores across those two groups. Since the primary goal of testing is to detect psychological variability, usually in terms of differences between people, an inability to compare people form different groups is a serious problem. If test users ignore this problem, then any decisions, interpretations, predicitons, or conclusions drawn from such comparisons are potentially flawed and psychologically unfounded.
- For example, imagine that we obtain scores on a test of mechanical aptitude, and that scores on this test suffered from construct bias related to biological sex. This finding would raise the possiblity that test scores reflect different psychological attributes in the two groups. If the mechanical aptitude test does not measure the same psychological attibutes for the two sexes, it would be inappropriate to compare a male's test score with a female's test score and use it to conclude, for example, the the male has greater mechanical aptitude. 
- Construct bias is evaluated by examining responses to individual items on a test. An item on a test is biased if:
      1. People belonging to different groups respond in different ways to the item, and
      2. These differing responses are not related to group differences in the psychological attribute measured by the test.

- Note that construct bias exists *only* if both facts are true: (a) there are group differences in the responses to an item *and* (b) those differences are not due to group differences in the priamry construct of interest. The fact that two groups have different responses to an item is, by itself, not evidence of bias.
- For composite tests, the overall test score bias is determined by the bias associated with each of the items or questions in the test: If we examine all of the items on a test and find none that seem to be biased, then we would assume that the total test score is unbiased. However, if one or more items do seem to be biased, then we would suspect that the total test score might also be biased to some degree.
- **Test bias concerns the relationship between group differences in true scores and group differences in observed test scores**. In the case of construct bias, a test item would be biased if responses to the item for people who belong to one group reflect their true scores on the relevant psychological attribute but responses to the item for people who belong to another group do not.
- Of course, we can never know a person's true score with respect to any attribute, so the procedures we use produce **estimates** of the existence and degree of construct bias.
- These procedures that use to estimate the existence and degree of construct bias **focus on the internal structure of the test: the way the parts of a test are related to each other**. In other words, internal structure refers to the pattern of correlations among items and/or the correlations between each item and the total test score.
- To evaluate the presence of construct bias, we examine the internal structure of a test separately for two groups. If the two groups show the same internal structure to their test responses, then we conclude that the test is unlikely to suffer from construct bias. However, if the two groups show different internal structures to their test responses, then we conclude that the test is likely to suffer from construct bias.

#### Reliability

- One way of evaluating construct bias is to estimate reliability separately for each group. One way of estimating reliability is through internal consistency (Cronbach's alpha). Internal consistency is based on the degree to which the parts of a test are consistent with each other. Therefore, alpha provides some insight into the internal structure of a test (e.g., are a test's items generally consistent with each other or not?)
- Therefore, group differences in reliability suggest that the test is not quite "working" in the same way in the two groups. if he test is more reliable in one group than in another, then the test provides observed scores that are more precise in one group that in the other. Thus we would have concerns about comparing the test scores between the two groups. In other words, we would be concerned about drawing robust conclusions based on comparing a set of precise test scores to a set of imprecise test scores.

#### Rank order

- If test items can be ranked in order to difficulty, then we can estimate construct bias. The rankings can be done separately for different groups.
- If the items' difficulty ranks differ across groups, then we would suspect that test score construct bias exists. We would suspect this because each item does not appear to be a measure of the same thing for both groups.
- We can use the ranks to compute Spearman's rank-order correlation coefficient, to reflect the rank-order consistenc across groups. If rho is low, we might suspect construct bias. 
- Note: The correlation between the ranks can be high even if the proportion of correct responses to each item differs across groups. For example, one group might be less likely than the other to give correct responses to the test questions, but the rank ordering of questions according to difficulty might be the same across groups. So, group differences in responding are not by themselves an indication of test score bias.

#### Item discrimination index

- We can detect consruct bias by computing item discrimination indexes separately for two groups.
- An item's discrimination index reflects the degree to which the item is related to the total test score (i.e. that people who answer an item correctly tend to do better inon the test as a whole than people who answer the item incorrectly). A strong discrimination indicates that an item is highly similar conceptually to most of the other items on a test. So, item discrimination indexes reflect the structure of associations among test items.
- **Example**: Suppose we give a test to a group of people, and use the scores to create two groups: a "high-scoring" group that has high scores on the test as a whole and a "low-scoring" group that has low scores on the test as a whole. What is the probability that people in the high-scoring group will answer a particular item correctly, and what is the probability that people in the low-scoring group will answer that item correctly?
      - The answer should depend on the degree to which that item is related to the construct being assessed by the test as a whole. So, if the item does indeed reflect the construct being assessed, then we would expect quite a high proportion of the high-scoring group to answer the item correctly and a relatively low proportion of the low-scoring group to answer the item correctly. Again, we would expect such results if the question/item is clearly related to the construct we are measuring. If the item is not clearly related to the construct, then we would not expect to find a difference between the high-scoring and low-scoring groups.
- The proportion of people who answer a question correctly can be used to compute an item discrimination index:
      - If people who score highly on the contruct being measured have a high probablity of answering a qustion/item correctly, while people who score low on the construct have a low probablity of answering the item correctly, then the question/item would have a high item discrimination index value. This would indicate that the item does indeed strongly discriminate among people with varying test scores. In turn, this would indicate that the item is a good reflection of the construct being measured.
      - In contrast, if people who have high test scores have nearly the same probablity of answering a particular question correctly, as compared with people who have low test scores, then the question would have a low item discrimination value. In this case, the item does not clearly discriminate among people with varying levels of the construct being measured.
- So, the item discrimination index can be used to estimate construct bias:
      1. We would select an item, compute its discrimination index separately for two groups of people, and then compare the groups' indexes.
      2. For example, we might want to know if an item on a test is biased in terms of gender. So, we compute an item discrimination index for males and for females. Specifically, we would determine the proportion of high-scoring males who answer the item correctly and the proportion of low-scoring males woh answer the item correctly. We would then use these proportions to determined the item's discrimination index for males.
      3. We would do the exact same procedure for females, in order to get the item's discrimination index for females.
      4. In the two discrimination index values are approximately equal, then this would indicate that the item reflects the construct in the same way for both genders (or for both groups, more generally). Thus, we might conclude that the item is not biased.
      5. But, if the two item discrimination index values are not approximately equal, then this would suggest that the item does not relfect the construct equally well for both groups, or that the item reflects slightly different constructs in males and in females. Such results would lead us to conclude that the item is probably biased in some way. So, we could conclude that the item belongs on the tes for one group but not for the other group.

#### Differential item functioning analyses

- We can also evaluate construct bias using a procedure called **differential item functioning analysis**.
- An important aspect of IRT is the assumption that it is possible to estimate respondents' trait levels directly from test data. In essence, the trait levels are participants' true scores for the psychological attribute that is being measured.
- If we assume that we can estimatethe trait levels for the people in two groups and if we have their responses to a particular test item, then we can see if the trait levels and the item responses match up in the same way for both groups. If they do not, then it is possible that the item is biased.
- **IRT is based on the idea that there is a mathematical function relating a participant's trait level/true score to the probability that they will respond to a particular test question in a certain way (e.g., correctly)**.
      - For **example**, we might observe that a person with a trait level that is 1 standard deviation above the mean has a .80 probability of answering a particular item correctly, whereas we might find that a person with a trait score that is 1 standard deviation below the mean has only a .20 probablity of answering the item correctly.
- If we have a group of people take a test and we know their respective trait levels, then we can generate an **item characteristic curve (ICC)** illustrating this mathematical function for each item. If we have two groups of people, then we can obtain ICCs separately for each group.
- To evaluate the presence of construct bias in an item, we would compare the item's ICC between the two groups.
- For **example**, consider two people who have the same trait level but who are from different groups. If the test is not biased, then those two people should have the same probability of answering the item correctly. However, if analyses (in an item characteristic curve) reveal that the two people actually have different probabilities of answering the item correctly, then the test might be biased. In other words, the probablity that two people will answer the item correctly might be different even if those two people have the same trait level (true score).
- We can draw ICC curves separately for two groups. If the curves overlap, then we might conclude that the item is not biased. However, if the curves differ/do not overlap, then it would lead us to suspect item bias.
- There can be two types of biases:
      1.**Uniform bias**: For example, females with the same score as males find an item more difficult to answer than females. Imagine that two people (man and woman) hve the same true score on a test, for example they are both 1 standard deviation above the mean. If the item is unbiased, then they should both have the same probablity of answering the item correctly (i.e. the item should be equally difficult or easy for both of them, since they have the same score on the test). However, if our analyses produce ICC curves that do not overlap, then this would imply that the item is easier for one person than for the other. This should be an obvious source of concern: if two people have the **same** level of ability but are **not** equally likely to answer the item correctly, then there is something wrong with the item. In other words, **there is something producing a bias**.
      2. **Nonuniform bias**: This refers to a situation in which this ICCs differ in *shape as well as location*. In this case, at some test score values, people in one group might find the item easier than people in another group who have the same test score. However, at other test scores, people in the first group find the item more difficult than people in the second group who have the same test score. That is, **in case of nonuniform bias, the exact consequence of bias differs depending on one's test score**.